---
title: "HW4"
author: "Mason Bosley"
date: "11/4/2021"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# library statements 
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(rpart.plot)
library(tidymodels) 
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)

nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")


nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
names(nba2021_2022salaries)[1] <- "Player"

nba2021pergame <- nba2021pergame %>% left_join(nba2021_2022salaries,by=c('Player')) %>%
  select(-AllStar)  %>%
  distinct(Player, .keep_all = TRUE) %>%
  filter(!is.na(Salary)) %>%
  na.omit()
head(nba2021pergame)
```

```{r}
# creation of cv folds

nba_cv10 <- vfold_cv(nba2021pergame, v = 10)

```

```{r, error=TRUE} 
#Decision Tree
nba2021pergame <- nba2021pergame %>%
mutate(Pos = stringr::str_replace(stringr::str_sub(Pos,1,2),"-",""))

nba2021pergame <- nba2021pergame %>%
  mutate(Pos = as.factor(Pos))
  
data_fold <- vfold_cv(nba2021pergame, v = 10)

data_rec <- recipe(Pos ~ G+GS +FG +FGA + MP + PTS +STL + BLK + Age + ORB + DRB + AST + WS + X3P. + X2P., data = nba2021pergame)

data_wf_tune <- workflow() %>%
  add_model(tree_spec) %>%
  add_recipe(data_rec)

param_grid <- grid_regular(cost_complexity(range = c(-5, -1)), levels = 10) 

tune_res <- tune_grid(
  data_wf_tune, 
  resamples = data_fold, 
  grid = param_grid, 
  metrics = metric_set(accuracy) #change this for regression trees
)

autoplot(tune_res) + theme_classic()

best_complexity <- select_by_one_std_err(tune_res, metric = 'accuracy', desc(cost_complexity))
best_complexity %>%
  pull(cost_complexity)
data_wf_final <- finalize_workflow(data_wf_tune, best_complexity)

pos_final_fit <- fit(data_wf_final, data = nba2021pergame)


tune_res %>% 
  collect_metrics() %>%
  filter(cost_complexity == best_complexity %>% pull(cost_complexity))

tree_mod_lowcp <- fit(
    data_wf_tune %>%
        update_model(tree_spec %>% set_args(cost_complexity = .0001)),
    data = nba2021pergame
)
tree_mod_highcp <- fit(
    data_wf_tune %>%
        update_model(tree_spec %>% set_args(cost_complexity = .03)),
    data = nba2021pergame
)

# Plot all 3 trees in a row
#par(mfrow = c(1,3))
tree_mod_lowcp %>% extract_fit_engine() %>% rpart.plot()
pos_final_fit %>% extract_fit_engine() %>% rpart.plot()
tree_mod_highcp %>% extract_fit_engine() %>% rpart.plot()
```

```{r, error=TRUE}
#Logistic

# Make sure you set reference level (to the outcome you are NOT interested in)
nba2021pergame <- nba2021pergame %>%
  mutate(nba2021pergame = relevel(factor(AllNBA), ref='0')) #set reference level

# Logistic Regression Model Spec
logistic_spec <- logistic_reg() %>%
    set_engine('glm') %>%
    set_mode('classification')

# Recipe
logistic_rec <- recipe(AllNBA ~ G+GS +FG +FGA + MP + PTS +STL + BLK + Age + ORB + DRB + AST + WS + X3P. + X2P., data = nba2021pergame)

# Workflow (Recipe + Model)
log_wf <- workflow() %>% 
    add_recipe(logistic_rec) %>%
    add_model(logistic_spec) 

# Fit Model
log_fit <- fit(log_wf, data = nba2021pergame)


```


```{r, error=TRUE}
#LASSO Logistic

# Make sure you set reference level (to the outcome you are NOT interested in)
nba2021pergame <- nba2021pergame %>%
  mutate(nba2021pergame = relevel(factor(AllNBA), ref='0')) #set reference level

nba_cv10 <- vfold_cv(nba2021pergame, v = 10)


# Logistic LASSO Regression Model Spec
logistic_lasso_spec_tune <- logistic_reg() %>%
    set_engine('glmnet') %>%
    set_args(mixture = 1, penalty = tune()) %>%
    set_mode('classification')

# Recipe
logistic_rec <- recipe(AllNBA ~ G+GS +FG +FGA + MP + PTS +STL + BLK + Age + ORB + DRB + AST + WS + X3P. + X2P., data = nba2021pergame) %>%
    step_normalize(all_numeric_predictors()) %>% 
    step_dummy(all_nominal_predictors())

# Workflow (Recipe + Model)
log_lasso_wf <- workflow() %>% 
    add_recipe(logistic_rec) %>%
    add_model(logistic_lasso_spec_tune) 

# Tune Model (trying a variety of values of Lambda penalty)
penalty_grid <- grid_regular(
  penalty(range = c(2, 7)), #log10 transformed  (kept moving min down from 0)
  levels = 20)

tune_output <- tune_grid( 
  log_lasso_wf, # workflow
  resamples = nba_cv10, # cv folds
  metrics = metric_set(roc_auc,accuracy),
  control = control_resamples(save_pred = TRUE, event_level = 'second'),
  grid = penalty_grid # penalty grid defined above
)

# Visualize Model Evaluation Metrics from Tuning
autoplot(tune_output) + theme_classic()
```
