# Recipe
data_rec <- recipe(Pos ~ FG +FGA + PTS +STL + BLK + Age + TOV + PF + ORB + DRB + TRB + AST + X3P + X3PA + X2P + X2PA + FT + FTA + FT., data = nba2021per36)
# Workflows
data_wf_mtry2 <- workflow() %>%
add_model(rf_spec %>% set_args(mtry = 2)) %>%
add_recipe(data_rec)
## Create workflows for mtry = 12, 74, and 147
data_wf_mtry12 <- workflow() %>%
add_model(rf_spec %>% set_args(mtry = 12)) %>%
add_recipe(data_rec)
data_wf_mtry74 <- workflow() %>%
add_model(rf_spec %>% set_args(mtry = 74)) %>%
add_recipe(data_rec)
data_wf_mtry147 <- workflow() %>%
add_model(rf_spec %>% set_args(mtry = 147)) %>%
add_recipe(data_rec)
# Fit Models
set.seed(123) # make sure to run this before each fit so that you have the same 1000 trees
data_fit_mtry2 <- fit(data_wf_mtry2, data = nba2021per36)
# Fit models for 12, 74, 147
set.seed(123)
data_fit_mtry12 <- fit(data_wf_mtry12, data = nba2021per36)
set.seed(123)
data_fit_mtry74 <- fit(data_wf_mtry74, data = nba2021per36)
set.seed(123)
data_fit_mtry147 <- fit(data_wf_mtry147, data = nba2021per36)
#Logistic
# Make sure you set reference level (to the outcome you are NOT interested in)
nba2021pergame <- nba2021pergame %>%
mutate(nba2021pergame = relevel(factor(AllNBA), ref='0')) #set reference level
# Logistic Regression Model Spec
logistic_spec <- logistic_reg() %>%
set_engine('glm') %>%
set_mode('classification')
# Recipe
logistic_rec <- recipe(AllNBA ~ G+GS +FG +FGA + MP + PTS +STL + BLK + Age + ORB + DRB + AST + WS + X3P. + X2P., data = nba2021pergame)
# Workflow (Recipe + Model)
log_wf <- workflow() %>%
add_recipe(logistic_rec) %>%
add_model(logistic_spec)
# Fit Model
log_fit <- fit(log_wf, data = nba2021pergame)
library(vip)
conflicted::conflict_prefer("vi", "vip")
rf_spec <- rand_forest() %>%
set_engine(engine = 'ranger') %>%
set_args(mtry = NULL, # size of random subset of variables; default is floor(sqrt(number of total predictors))
trees = 1000, # Number of trees
min_n = 2,
probability = FALSE, # FALSE: get hard predictions (not needed for regression)
importance = 'impurity') %>% # we'll come back to this at the end
set_mode('classification') # change this for regression
library(vip)
conflicted::conflict_prefer("vi", "vip")
rf_spec <- rand_forest() %>%
set_engine(engine = 'ranger') %>%
set_args(mtry = NULL, # size of random subset of variables; default is floor(sqrt(number of total predictors))
trees = 1000, # Number of trees
min_n = 2,
probability = FALSE, # FALSE: get hard predictions (not needed for regression)
importance = 'impurity') %>% # we'll come back to this at the end
set_mode('classification') # change this for regression
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
# library statements
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(rpart.plot)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)
nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")
nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
names(nba2021_2022salaries)[1] <- "Player"
nba2021pergame <- nba2021pergame %>% left_join(nba2021_2022salaries,by=c('Player')) %>%
select(-AllStar)  %>%
distinct(Player, .keep_all = TRUE) %>%
filter(!is.na(Salary)) %>%
na.omit()
nba2021pergame <- nba2021pergame %>%
mutate(Pos = stringr::str_replace(stringr::str_sub(Pos,1,2),"-",""))
head(nba2021pergame)
# data cleaning
# creation of cv folds
nba_cv10 <- vfold_cv(nba2021pergame, v = 10)
# model spec
lm_spec <-
linear_reg() %>%
set_engine(engine = 'lm') %>%
set_mode('regression')
lm_lasso_spec_tune <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso
set_engine(engine = 'glmnet') %>% #note we are using a different engine
set_mode('regression')
knn_spec <-
nearest_neighbor() %>% # new type of model!
set_args(neighbors = tune()) %>% # tuning parameter is neighbor; tuning spec
set_engine(engine = 'kknn') %>% # new engine
set_mode('regression')
tree_spec <- decision_tree() %>%
set_engine(engine = 'rpart') %>%
set_args(cost_complexity = tune(),
min_n = 2,
tree_depth = NULL) %>%
set_mode('classification')
# recipes & workflows
mod1 <- fit(lm_spec,
Salary ~ G+GS +FG +FGA + MP + PTS +STL + BLK + Age + ORB + DRB + AST + X3P. + X2P., data = nba2021pergame)
full_rec <- recipe(Salary ~ G+ GS +FG +FGA + MP + PTS +STL + BLK + Age + TOV + PF + ORB + DRB + TRB + AST + X3P + X3PA + X2P + X2PA + FT + FTA + FT., data = nba2021pergame) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
knn_rec <- recipe(Salary ~ . , data = nba2021pergame) %>%
step_nzv(all_predictors()) %>%
step_novel(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
knn_wf <- workflow() %>%
add_model(knn_spec) %>%
add_recipe(knn_rec)
# fit & tune models
penalty_grid <- grid_regular(
penalty(range = c(3, 7)), #log10 transformed
levels = 10)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(mae),
grid = penalty_grid # penalty grid defined above
)
nbatune_output
mod1 %>% tidy()
best_se_penalty <- select_by_one_std_err(nbatune_output, metric = 'mae', desc(penalty))
best_se_penalty
final_wf_se <- finalize_workflow(lasso_wf_tune, best_se_penalty) # incorporates penalty value to workflow
final_fit_se <- fit(final_wf_se, data = nba2021pergame)
tidy(final_fit_se)
glmnet_output <- final_fit_se %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output
lambdas <- glmnet_output$lambda
coefs_lambdas <-
coefficients(glmnet_output, s = lambdas )  %>%
as.matrix() %>%
t() %>%
as.data.frame() %>%
mutate(lambda = lambdas ) %>%
select(lambda, everything(), -`(Intercept)`) %>%
pivot_longer(cols = -lambda,
names_to = "term",
values_to = "coef") %>%
mutate(var = purrr::map_chr(stringr::str_split(term,"_"),~.[1]))
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8)) +
xlim(0,8000000) + ylim(-2000000,5000000)
# visual residuals
mod1_output <- mod1 %>%
predict(new_data = nba2021pergame) %>%
bind_cols(nba2021pergame) %>%
mutate(resid = Salary - .pred)
ggplot(mod1_output, aes(x = .pred, y = resid)) +
geom_point() +
geom_smooth() +
geom_hline(yintercept = 0, color = "red") +
theme_classic()
nba2021per36 <- nba2021per36 %>%
mutate(Pos = stringr::str_replace(stringr::str_sub(Pos,1,2),"-",""))
nba2021per36 <- read.csv("Per36-Player.csv")
nba2021per36 <- nba2021per36 %>% left_join(nba2021_2022salaries,by=c('Player')) %>%
select(-AllStar)  %>%
distinct(Player, .keep_all = TRUE) %>%
filter(!is.na(Salary)) %>%
filter(MP > 300) %>%
na.omit()
nba2021per36 <- nba2021per36 %>%
mutate(Pos = stringr::str_replace(stringr::str_sub(Pos,1,2),"-",""))
nba2021per36 <- nba2021per36 %>%
mutate(Pos = as.factor(Pos))
data_fold <- vfold_cv(nba2021per36, v = 10)
data_rec <- recipe(Pos ~ FG +FGA + FT. + PTS +STL + BLK + ORB + DRB + AST + X3P. + X2P. + TOV, data = nba2021per36)
data_wf_tune <- workflow() %>%
add_model(tree_spec) %>%
add_recipe(data_rec)
param_grid <- grid_regular(cost_complexity(range = c(-5, -1)), levels = 10)
tune_res <- tune_grid(
data_wf_tune,
resamples = data_fold,
grid = param_grid,
metrics = metric_set(accuracy) #change this for regression trees
)
autoplot(tune_res) + theme_classic()
best_complexity <- select_by_one_std_err(tune_res, metric = 'accuracy', desc(cost_complexity))
best_complexity %>%
pull(cost_complexity)
data_wf_final <- finalize_workflow(data_wf_tune, best_complexity)
pos_final_fit <- fit(data_wf_final, data = nba2021per36)
tune_res %>%
collect_metrics() %>%
filter(cost_complexity == best_complexity %>% pull(cost_complexity))
tree_mod_lowcp <- fit(
data_wf_tune %>%
update_model(tree_spec %>% set_args(cost_complexity = .0001)),
data = nba2021per36
)
tree_mod_highcp <- fit(
data_wf_tune %>%
update_model(tree_spec %>% set_args(cost_complexity = .018)),
data = nba2021per36
)
# Plot all 3 trees in a row
#par(mfrow = c(1,3))
tree_mod_lowcp %>% extract_fit_engine() %>% rpart.plot()
pos_final_fit %>% extract_fit_engine() %>% rpart.plot()
tree_mod_highcp %>% extract_fit_engine() %>% rpart.plot()
library(vip)
conflicted::conflict_prefer("vi", "vip")
rf_spec <- rand_forest() %>%
set_engine(engine = 'ranger') %>%
set_args(mtry = NULL, # size of random subset of variables; default is floor(sqrt(number of total predictors))
trees = 1000, # Number of trees
min_n = 2,
probability = FALSE, # FALSE: get hard predictions (not needed for regression)
importance = 'impurity') %>% # we'll come back to this at the end
set_mode('classification') # change this for regression
# Recipe
data_rec <- recipe(Pos ~ FG +FGA + PTS +STL + BLK + Age + TOV + PF + ORB + DRB + TRB + AST + X3P + X3PA + X2P + X2PA + FT + FTA + FT., data = nba2021per36)
# Workflows
data_wf_mtry2 <- workflow() %>%
add_model(rf_spec %>% set_args(mtry = 2)) %>%
add_recipe(data_rec)
## Create workflows for mtry = 12, 74, and 147
data_wf_mtry7 <- workflow() %>%
add_model(rf_spec %>% set_args(mtry = 7)) %>%
add_recipe(data_rec)
data_wf_mtry12 <- workflow() %>%
add_model(rf_spec %>% set_args(mtry = 12)) %>%
add_recipe(data_rec)
data_wf_mtry19 <- workflow() %>%
add_model(rf_spec %>% set_args(mtry = 19)) %>%
add_recipe(data_rec)
# Fit Models
set.seed(123) # make sure to run this before each fit so that you have the same 1000 trees
data_fit_mtry2 <- fit(data_wf_mtry2, data = nba2021per36)
# Fit models for 12, 74, 147
set.seed(123)
data_fit_mtry7 <- fit(data_wf_mtry7, data = nba2021per36)
set.seed(123)
data_fit_mtry12 <- fit(data_wf_mtry12, data = nba2021per36)
set.seed(123)
data_fit_mtry19 <- fit(data_wf_mtry19, data = nba2021per36)
# Custom Function to get OOB predictions, true observed outcomes and add a user-provided model label
rf_OOB_output <- function(fit_model, model_label, truth){
tibble(
.pred_class = fit_model %>% extract_fit_engine() %>% pluck('predictions'), #OOB predictions
class = truth,
label = model_label
)
}
#check out the function output
rf_OOB_output(data_fit_mtry2,2, nba2021per36 %>% pull(Pos))
# Evaluate OOB Metrics
data_rf_OOB_output <- bind_rows(
rf_OOB_output(data_fit_mtry2,2, nba2021per36 %>% pull(Pos)),
rf_OOB_output(data_fit_mtry7,7, nba2021per36 %>% pull(Pos)),
rf_OOB_output(data_fit_mtry12,12, nba2021per36 %>% pull(Pos)),
rf_OOB_output(data_fit_mtry19,19, nba2021per36 %>% pull(Pos))
)
data_rf_OOB_output %>%
group_by(label) %>%
accuracy(truth = class, estimate = .pred_class)
# Evaluate OOB Metrics
data_rf_OOB_output <- bind_rows(
rf_OOB_output(data_fit_mtry2,2, nba2021per36 %>% pull(Pos)),
rf_OOB_output(data_fit_mtry7,7, nba2021per36 %>% pull(Pos)),
rf_OOB_output(data_fit_mtry12,12, nba2021per36 %>% pull(Pos)),
rf_OOB_output(data_fit_mtry19,19, nba2021per36 %>% pull(Pos))
)
data_rf_OOB_output %>%
group_by(label) %>%
accuracy(truth = Pos, estimate = .pred_class)
# Evaluate OOB Metrics
data_rf_OOB_output <- bind_rows(
rf_OOB_output(data_fit_mtry2,2, nba2021per36 %>% pull(Pos)),
rf_OOB_output(data_fit_mtry7,7, nba2021per36 %>% pull(Pos)),
rf_OOB_output(data_fit_mtry12,12, nba2021per36 %>% pull(Pos)),
rf_OOB_output(data_fit_mtry19,19, nba2021per36 %>% pull(Pos))
)
data_rf_OOB_output %>%
group_by(label) %>%
accuracy(truth = class, estimate = .pred_class)
data_fit_mtry12
rf_OOB_output(data_fit_mtry12,12, land %>% pull(class)) %>%
conf_mat(truth = class, estimate= .pred_class)
rf_OOB_output(data_fit_mtry12,12, nba2021per36 %>% pull(Pos)) %>%
conf_mat(truth = class, estimate= .pred_class)
data_fit_mtry7
rf_OOB_output(data_fit_mtry7,7, nba2021per36 %>% pull(Pos)) %>%
conf_mat(truth = class, estimate= .pred_class)
#LASSO Logistic
# Make sure you set reference level (to the outcome you are NOT interested in)
nba2021pergame <- nba2021pergame %>%
mutate(nba2021pergame = relevel(factor(AllNBA), ref='0')) #set reference level
nba_cv10 <- vfold_cv(nba2021pergame, v = 10)
# Logistic LASSO Regression Model Spec
logistic_lasso_spec_tune <- logistic_reg() %>%
set_engine('glmnet') %>%
set_args(mixture = 1, penalty = tune()) %>%
set_mode('classification')
# Recipe
logistic_rec <- recipe(AllNBA ~ G+GS +FG +FGA + MP + PTS +STL + BLK + Age + ORB + DRB + AST + WS + X3P. + X2P., data = nba2021pergame) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
# Workflow (Recipe + Model)
log_lasso_wf <- workflow() %>%
add_recipe(logistic_rec) %>%
add_model(logistic_lasso_spec_tune)
# Tune Model (trying a variety of values of Lambda penalty)
penalty_grid <- grid_regular(
penalty(range = c(2, 7)), #log10 transformed  (kept moving min down from 0)
levels = 20)
tune_output <- tune_grid(
log_lasso_wf, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(roc_auc,accuracy),
control = control_resamples(save_pred = TRUE, event_level = 'second'),
grid = penalty_grid # penalty grid defined above
)
# Visualize Model Evaluation Metrics from Tuning
autoplot(tune_output) + theme_classic()
ggplot(nba2021pergame, aes(x=ORB,y=X3P.)) +
geom_point()
nba_sub <- nba2021pergame %>%
select(ORB, X3P., )
# Run k-means for k = centers = 3
set.seed(253)
kclust_k5 <- kmeans(nba_sub, centers = 5)
# Display the cluter assignments
kclust_k5$cluster
# Add a variable (kclust_3) to the original dataset
# containing the cluster assignments
nba_clust <- nba2021pergame %>%
mutate(kclust_5 = factor(kclust_k5$cluster))
ggplot(nba_clust, aes(x=ORB,y=X3P., colour = kclust_5)) +
geom_point()
knitr::opts_chunk$set(echo = TRUE)
lm_lasso_spec_tune <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>%
set_engine(engine = 'glmnet') %>%
set_mode('regression')
full_rec <- recipe(Salary ~ G+ GS +FG +FGA + MP + PTS +STL + BLK + Age + TOV + PF + ORB + DRB + TRB + AST + X3P + X3PA + X2P + X2PA + FT + FTA + FT., data = nba2021pergame) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
penalty_grid <- grid_regular(
penalty(range = c(3, 7)), #log10 transformed
levels = 10)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(mae),
grid = penalty_grid # penalty grid defined above
)
best_se_penalty <- select_by_one_std_err(nbatune_output, metric = 'mae', desc(penalty))
best_se_penalty
final_wf_se <- finalize_workflow(lasso_wf_tune, best_se_penalty) # incorporates penalty value to workflow
final_fit_se <- fit(final_wf_se, data = nba2021pergame)
tidy(final_fit_se)
glmnet_output <- final_fit_se %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output
lambdas <- glmnet_output$lambda
coefs_lambdas <-
coefficients(glmnet_output, s = lambdas )  %>%
as.matrix() %>%
t() %>%
as.data.frame() %>%
mutate(lambda = lambdas ) %>%
select(lambda, everything(), -`(Intercept)`) %>%
pivot_longer(cols = -lambda,
names_to = "term",
values_to = "coef") %>%
mutate(var = purrr::map_chr(stringr::str_split(term,"_"),~.[1]))
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8)) +
xlim(0,8000000) + ylim(-2000000,5000000)
lm_lasso_spec_tune <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>%
set_engine(engine = 'glmnet') %>%
set_mode('regression')
full_rec <- recipe(Salary ~ G+ GS +FG +FGA + FG.+ MP + PTS +STL + BLK + Age + TOV + PF + ORB + DRB + TRB + AST + X3P + X3PA + X3P. + X2P + X2PA + FT + FTA + FT., data = nba2021pergame) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
penalty_grid <- grid_regular(
penalty(range = c(3, 7)), #log10 transformed
levels = 10)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(mae),
grid = penalty_grid # penalty grid defined above
)
best_se_penalty <- select_by_one_std_err(nbatune_output, metric = 'mae', desc(penalty))
best_se_penalty
final_wf_se <- finalize_workflow(lasso_wf_tune, best_se_penalty) # incorporates penalty value to workflow
final_fit_se <- fit(final_wf_se, data = nba2021pergame)
tidy(final_fit_se)
glmnet_output <- final_fit_se %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output
lambdas <- glmnet_output$lambda
coefs_lambdas <-
coefficients(glmnet_output, s = lambdas )  %>%
as.matrix() %>%
t() %>%
as.data.frame() %>%
mutate(lambda = lambdas ) %>%
select(lambda, everything(), -`(Intercept)`) %>%
pivot_longer(cols = -lambda,
names_to = "term",
values_to = "coef") %>%
mutate(var = purrr::map_chr(stringr::str_split(term,"_"),~.[1]))
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8)) +
xlim(0,8000000) + ylim(-2000000,5000000)
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8)) +
xlim(0,8000000) + ylim(-2500000,5000000)
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8)) +
xlim(0,7500000) + ylim(-2500000,5000000)
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8)) +
xlim(0,7700000) + ylim(-2500000,5000000)
lm_lasso_spec_tune <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>%
set_engine(engine = 'glmnet') %>%
set_mode('regression')
full_rec <- recipe(Salary ~ G+ GS +FG +FGA + FG.+ MP + PTS +STL + BLK + Age + TOV + PF + ORB + DRB + TRB + AST + X3P + X3PA + X3P. + X2P + X2PA + FT + FTA + FT. + WS, data = nba2021pergame) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
penalty_grid <- grid_regular(
penalty(range = c(3, 7)), #log10 transformed
levels = 10)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(mae),
grid = penalty_grid # penalty grid defined above
)
best_se_penalty <- select_by_one_std_err(nbatune_output, metric = 'mae', desc(penalty))
best_se_penalty
final_wf_se <- finalize_workflow(lasso_wf_tune, best_se_penalty) # incorporates penalty value to workflow
final_fit_se <- fit(final_wf_se, data = nba2021pergame)
tidy(final_fit_se)
glmnet_output <- final_fit_se %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output
lambdas <- glmnet_output$lambda
coefs_lambdas <-
coefficients(glmnet_output, s = lambdas )  %>%
as.matrix() %>%
t() %>%
as.data.frame() %>%
mutate(lambda = lambdas ) %>%
select(lambda, everything(), -`(Intercept)`) %>%
pivot_longer(cols = -lambda,
names_to = "term",
values_to = "coef") %>%
mutate(var = purrr::map_chr(stringr::str_split(term,"_"),~.[1]))
coefs_lambdas %>%
ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
geom_line() +
geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') +
theme_classic() +
theme(legend.position = "bottom", legend.text=element_text(size=8)) +
xlim(0,7700000) + ylim(-2500000,5000000)
