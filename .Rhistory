step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
# fit & tune models
penalty_grid <- grid_regular(
penalty(range = c(-5, 1)), #log10 transformed
levels = 50)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(rmse, mae, rsq),
grid = penalty_grid # penalty grid defined above
)
nbatune_output
autoplot(nbatune_output)
# recipes & workflows
full_rec <- recipe(AllNBA ~ .-Player-Pos-A..-Tm, data = nba_clean) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors())
# recipes & workflows
full_rec <- recipe(AllNBA ~ ., data = nba_clean) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors())%>%
step_rm(Player)%>%
step_rm(Pos)%>%
step_rm(A..)%>%
step_rm(Tm)
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
# fit & tune models
penalty_grid <- grid_regular(
penalty(range = c(-5, 1)), #log10 transformed
levels = 50)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(rmse, mae, rsq),
grid = penalty_grid # penalty grid defined above
)
nbatune_output
autoplot(nbatune_output)
# recipes & workflows
full_rec <- recipe(AllNBA ~ ., data = nba_clean) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors())%>%
step_rm(Player)%>%
step_rm(Pos)%>%
step_rm(A..)%>%
step_rm(Tm)%>%
step_rm(AllStar)
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
# fit & tune models
penalty_grid <- grid_regular(
penalty(range = c(-5, 1)), #log10 transformed
levels = 50)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(rmse, mae, rsq),
grid = penalty_grid # penalty grid defined above
)
nbatune_output
autoplot(nbatune_output)
# recipes & workflows
full_rec <- recipe(AllNBA ~ ., data = nba_clean) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors())%>%
step_rm(Player)%>%
step_rm(Pos)%>%
step_rm(A...)%>%
step_rm(Tm)%>%
step_rm(AllStar)
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
# fit & tune models
penalty_grid <- grid_regular(
penalty(range = c(-5, 1)), #log10 transformed
levels = 50)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(rmse, mae, rsq),
grid = penalty_grid # penalty grid defined above
)
nbatune_output
autoplot(nbatune_output)
# library statements
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)
nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")
head(nba2021pergame)
View(nba2021pergame)
# recipes & workflows
full_rec <- recipe(AllNBA ~ ., data = nba_clean) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors())
# data cleaning
nba_clean <-
nba2021pergame %>% distinct(Player, .keep_all = TRUE) %>%
select(-ï..Rk)
# creation of cv folds
nba_cv10 <- vfold_cv(nba_clean, v = 10)
# model spec
lm_spec <-
linear_reg() %>%
set_engine(engine = 'lm') %>%
set_mode('regression')
lm_lasso_spec_tune <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso
set_engine(engine = 'glmnet') %>% #note we are using a different engine
set_mode('regression')
knn_spec <-
nearest_neighbor() %>% # new type of model!
set_args(neighbors = tune()) %>% # tuning parameter is neighbor; tuning spec
set_engine(engine = 'kknn') %>% # new engine
set_mode('regression')
# recipes & workflows
full_rec <- recipe(AllNBA ~ ., data = nba_clean) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors())
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
knn_rec <- recipe( AllNBA ~ . , data = nba_clean) %>%
step_nzv(all_predictors()) %>%
step_novel(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
knn_wf <- workflow() %>%
add_model(knn_spec) %>%
add_recipe(knn_rec)
# fit & tune models
penalty_grid <- grid_regular(
penalty(range = c(-5, 1)), #log10 transformed
levels = 50)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(rmse, mae, rsq),
grid = penalty_grid # penalty grid defined above
)
nbatune_output
autoplot(nbatune_output)
#  calculate/collect CV metrics
best_penalty <- select_best(nbatune_output, metric = 'mae')
# library statements
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)
nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")
head(nba2021pergame)
nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
View(nba2021_2022salaries)
knitr::opts_chunk$set(echo=TRUE, eval=FALSE)
# library statements
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)
nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")
head(nba2021pergame)
nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
# data cleaning
nba_clean <-
nba2021pergame %>% distinct(Player, .keep_all = TRUE) %>%
select(-ï..Rk)
# creation of cv folds
nba_cv10 <- vfold_cv(nba_clean, v = 10)
# model spec
lm_spec <-
linear_reg() %>%
set_engine(engine = 'lm') %>%
set_mode('regression')
lm_lasso_spec_tune <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso
set_engine(engine = 'glmnet') %>% #note we are using a different engine
set_mode('regression')
knn_spec <-
nearest_neighbor() %>% # new type of model!
set_args(neighbors = tune()) %>% # tuning parameter is neighbor; tuning spec
set_engine(engine = 'kknn') %>% # new engine
set_mode('regression')
# recipes & workflows
full_rec <- recipe(AllNBA ~ ., data = nba_clean) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors())
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
knn_rec <- recipe( AllNBA ~ . , data = nba_clean) %>%
step_nzv(all_predictors()) %>%
step_novel(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
knn_wf <- workflow() %>%
add_model(knn_spec) %>%
add_recipe(knn_rec)
# fit & tune models
penalty_grid <- grid_regular(
penalty(range = c(-5, 1)), #log10 transformed
levels = 50)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(rmse, mae, rsq),
grid = penalty_grid # penalty grid defined above
)
nbatune_output
autoplot(nbatune_output)
# library statements
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)
nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")
head(nba2021pergame)
nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
View(nba2021_2022salaries)
View(nba2021_2022salaries)
View(nba2021pergame)
nba2021pergame %>% left_join(nba2021_2022salaries)
nba2021pergame %>% left_join(nba2021_2022salaries,by=c('Player'))
# library statements
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)
nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")
head(nba2021pergame)
nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
nba2021pergame <- nba2021pergame %>% left_join(nba2021_2022salaries,by=c('Player')) %>% select(-Tm.y,-ï..Rk.y)
nba2021pergame <- nba2021pergame %>% left_join(nba2021_2022salaries,by=c('Player')) %>% select(-Tm.y,-ï..Rk.y)
# library statements
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)
nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")
head(nba2021pergame)
nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
nba2021pergame <- nba2021pergame %>% left_join(nba2021_2022salaries,by=c('Player')) %>% select(-Tm.y,-ï..Rk.y)
head(nba2021pergame)
# library statements
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)
nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")
nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
nba2021pergame <- nba2021pergame %>% left_join(nba2021_2022salaries,by=c('Player')) %>% select(-Tm.y,-ï..Rk.y) %>%
filter(!is.na(Salary))
head(nba2021pergame)
# library statements
# read in data
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(tidymodels)
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)
nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")
nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
names(nba2021_2022salaries)[1] <- "Player"
nba2021pergame <- nba2021pergame %>% left_join(nba2021_2022salaries,by=c('Player')) %>%
select(-AllStar)  %>%
distinct(Player, .keep_all = TRUE) %>%
filter(!is.na(Salary)) %>%
na.omit()
head(nba2021pergame)
# creation of cv folds
nba_cv10 <- vfold_cv(nba2021pergame, v = 10)
# model spec
lm_spec <-
linear_reg() %>%
set_engine(engine = 'lm') %>%
set_mode('regression')
lm_lasso_spec_tune <-
linear_reg() %>%
set_args(mixture = 1, penalty = tune()) %>% ## mixture = 1 indicates Lasso
set_engine(engine = 'glmnet') %>% #note we are using a different engine
set_mode('regression')
knn_spec <-
nearest_neighbor() %>% # new type of model!
set_args(neighbors = tune()) %>% # tuning parameter is neighbor; tuning spec
set_engine(engine = 'kknn') %>% # new engine
set_mode('regression')
tree_spec <- decision_tree() %>%
set_engine(engine = 'rpart') %>%
set_args(cost_complexity = tune(),
min_n = 2,
tree_depth = NULL) %>%
set_mode('classification')
# recipes & workflows
mod1 <- fit(lm_spec,
Salary ~ G+GS +FG +FGA + MP + PTS +STL + BLK + Age + ORB + DRB + AST + WS + X3P. + X2P., data = nba2021pergame)
full_rec <- recipe(Salary ~ G+ GS +FG +FGA + MP + PTS +STL + BLK + Age + TOV + PF + ORB + DRB + TRB + AST + WS + X3P + X3PA + X2P + X2PA + FT + FTA + FT., data = nba2021pergame) %>%
step_nzv(all_predictors()) %>% # removes variables with the same value
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
lasso_wf_tune <- workflow() %>%
add_recipe(full_rec) %>% # recipe defined above
add_model(lm_lasso_spec_tune)
knn_rec <- recipe(Salary ~ . , data = nba2021pergame) %>%
step_nzv(all_predictors()) %>%
step_novel(all_nominal_predictors()) %>%
step_normalize(all_numeric_predictors()) %>%
step_dummy(all_nominal_predictors())
knn_wf <- workflow() %>%
add_model(knn_spec) %>%
add_recipe(knn_rec)
# fit & tune models
penalty_grid <- grid_regular(
penalty(range = c(3, 7)), #log10 transformed
levels = 10)
nbatune_output <- tune_grid( # new function for tuning parameters
lasso_wf_tune, # workflow
resamples = nba_cv10, # cv folds
metrics = metric_set(mae),
grid = penalty_grid # penalty grid defined above
)
nbatune_output
nba2021pergame <- nba2021pergame %>%
mutate(Pos = stringr::str_replace(stringr::str_sub(Pos,1,2),"-",""))
nba2021pergame <- nba2021pergame %>%
mutate(Pos = as.factor(Pos))
data_fold <- vfold_cv(nba2021pergame, v = 10)
data_rec <- recipe(Pos ~ ., data = nba2021pergame)
data_wf_tune <- workflow() %>%
add_model(tree_spec) %>%
add_recipe(data_rec)
tune_res <- tune_grid(
data_wf_tune,
resamples = data_fold,
grid = param_grid,
metrics = metric_set(accuracy) #change this for regression trees
)
nba2021pergame <- nba2021pergame %>%
mutate(Pos = stringr::str_replace(stringr::str_sub(Pos,1,2),"-",""))
nba2021pergame <- nba2021pergame %>%
mutate(Pos = as.factor(Pos))
data_fold <- vfold_cv(nba2021pergame, v = 10)
data_rec <- recipe(Pos ~ G+GS +FG +FGA + MP + PTS +STL + BLK + Age + ORB + DRB + AST + WS + X3P. + X2P., data = nba2021pergame)
data_wf_tune <- workflow() %>%
add_model(tree_spec) %>%
add_recipe(data_rec)
param_grid <- grid_regular(cost_complexity(range = c(-5, -1)), levels = 10)
tune_res <- tune_grid(
data_wf_tune,
resamples = data_fold,
grid = param_grid,
metrics = metric_set(accuracy) #change this for regression trees
)
autoplot(tune_res) + theme_classic()
best_complexity <- select_by_one_std_err(tune_res, metric = 'accuracy', desc(cost_complexity))
best_complexity %>%
pull(cost_complexity)
data_wf_final <- finalize_workflow(data_wf_tune, best_complexity)
land_final_fit <- fit(data_wf_final, data = land)
# Make sure you understand what each line of code is doing
set.seed(123) # don't change this
data_fold <- vfold_cv(land, v = 10)
library(dplyr)
library(readr)
library(ggplot2)
library(rpart.plot)
library(tidymodels)
tidymodels_prefer()
# Read in the data
land <- read_csv("https://www.macalester.edu/~ajohns24/data/land_cover.csv")
# There are 9 land types, but we'll focus on 3 of them
land <- land %>%
filter(class %in% c("asphalt", "grass", "tree"))
# Make sure you understand what each line of code is doing
set.seed(123) # don't change this
data_fold <- vfold_cv(land, v = 10)
ct_spec_tune <- decision_tree() %>%
set_engine(engine = 'rpart') %>%
set_args(cost_complexity = tune(),
min_n = 2,
tree_depth = NULL) %>%
set_mode('classification')
data_rec <- recipe(class ~ ., data = land)
data_wf_tune <- workflow() %>%
add_model(ct_spec_tune) %>%
add_recipe(data_rec)
param_grid <- grid_regular(cost_complexity(range = c(-5, -1)), levels = 10)
tune_res <- tune_grid(
data_wf_tune,
resamples = data_fold,
grid = param_grid,
metrics = metric_set(accuracy) #change this for regression trees
)
best_complexity <- select_by_one_std_err(tune_res, metric = 'accuracy', desc(cost_complexity))
best_complexity %>%
pull(cost_complexity)
data_wf_final <- finalize_workflow(data_wf_tune, best_complexity)
pos_final_fit <- fit(data_wf_final, data = nba2021pergame)
nba2021pergame <- nba2021pergame %>%
mutate(Pos = stringr::str_replace(stringr::str_sub(Pos,1,2),"-",""))
nba2021pergame <- nba2021pergame %>%
mutate(Pos = as.factor(Pos))
data_fold <- vfold_cv(nba2021pergame, v = 10)
data_rec <- recipe(Pos ~ G+GS +FG +FGA + MP + PTS +STL + BLK + Age + ORB + DRB + AST + WS + X3P. + X2P., data = nba2021pergame)
data_wf_tune <- workflow() %>%
add_model(tree_spec) %>%
add_recipe(data_rec)
param_grid <- grid_regular(cost_complexity(range = c(-5, -1)), levels = 10)
tune_res <- tune_grid(
data_wf_tune,
resamples = data_fold,
grid = param_grid,
metrics = metric_set(accuracy) #change this for regression trees
)
best_complexity <- select_by_one_std_err(tune_res, metric = 'accuracy', desc(cost_complexity))
best_complexity %>%
pull(cost_complexity)
data_wf_final <- finalize_workflow(data_wf_tune, best_complexity)
pos_final_fit <- fit(data_wf_final, data = nba2021pergame)
tune_res %>%
collect_metrics() %>%
filter(cost_complexity == best_complexity %>% pull(cost_complexity))
tree_mod_lowcp <- fit(
data_wf_tune %>%
update_model(tree_spec %>% set_args(cost_complexity = .00001)),
data = nba2021pergame
)
tree_mod_highcp <- fit(
data_wf_tune %>%
update_model(tree_spec %>% set_args(cost_complexity = .1)),
data = nba2021pergame
)
# Plot all 3 trees in a row
#par(mfrow = c(1,3))
tree_mod_lowcp %>% extract_fit_engine() %>% rpart.plot()
land_final_fit %>% extract_fit_engine() %>% rpart.plot()
tree_mod_lowcp %>% extract_fit_engine() %>% rpart.plot()
pos_final_fit %>% extract_fit_engine() %>% rpart.plot()
tree_mod_highcp %>% extract_fit_engine() %>% rpart.plot()
e_res %>%
collect_metrics() %>%
filter(cost_complexity == best_complexity %>% pull(cost_complexity))
tune_res %>%
collect_metrics() %>%
filter(cost_complexity == best_complexity %>% pull(cost_complexity))
tree_mod_lowcp <- fit(
data_wf_tune %>%
update_model(tree_spec %>% set_args(cost_complexity = .0001)),
data = nba2021pergame
)
tree_mod_highcp <- fit(
data_wf_tune %>%
update_model(tree_spec %>% set_args(cost_complexity = .01)),
data = nba2021pergame
)
# Plot all 3 trees in a row
#par(mfrow = c(1,3))
tree_mod_lowcp %>% extract_fit_engine() %>% rpart.plot()
pos_final_fit %>% extract_fit_engine() %>% rpart.plot()
tree_mod_highcp %>% extract_fit_engine() %>% rpart.plot()
tree_mod_highcp %>% extract_fit_engine() %>% rpart.plot()
tree_mod_highcp <- fit(
data_wf_tune %>%
update_model(tree_spec %>% set_args(cost_complexity = .005)),
data = nba2021pergame
)
tree_mod_highcp %>% extract_fit_engine() %>% rpart.plot()
tree_mod_highcp <- fit(
data_wf_tune %>%
update_model(tree_spec %>% set_args(cost_complexity = .05)),
data = nba2021pergame
)
tree_mod_highcp %>% extract_fit_engine() %>% rpart.plot()
