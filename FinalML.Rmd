---
title: "ML Final Project"
author: "Mason Bosley, Lou Miller"
date: "12/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(dplyr)
library(readr)
library(broom)
library(ggplot2)
library(rpart.plot)
library(tidymodels) 
tidymodels_prefer() # Resolves conflicts, prefers tidymodel functions
set.seed(123)

nba2021pergame <- read.csv("2021-PerGame-Player-Stats.csv")


nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
names(nba2021_2022salaries)[1] <- "Player"

nba2021pergame <- nba2021pergame %>% left_join(nba2021_2022salaries,by=c('Player')) %>%
  select(-AllStar)  %>%
  distinct(Player, .keep_all = TRUE) %>%
  filter(!is.na(Salary)) %>%
  na.omit()
head(nba2021pergame)
```


REGRESSION
```{r}
nba2021pergame %>%
    ggplot(aes(x = WS, y = Salary, color = AllNBA)) + 
    geom_point(alpha = 0.2) + 
    geom_smooth(span = 0.8, se = FALSE) +
    theme_classic()
```

LASSO
```{r}
lm_lasso_spec_tune <- 
  linear_reg() %>%
  set_args(mixture = 1, penalty = tune()) %>% 
  set_engine(engine = 'glmnet') %>% 
  set_mode('regression')

full_rec <- recipe(Salary ~ G+ GS +FG +FGA + FG.+ MP + PTS +STL + BLK + Age + TOV + PF + ORB + DRB + TRB + AST + X3P + X3PA + X3P. + X2P + X2PA + FT + FTA + FT. + WS, data = nba2021pergame) %>%
  step_nzv(all_predictors()) %>% # removes variables with the same value
  step_normalize(all_numeric_predictors()) %>% 
  step_dummy(all_nominal_predictors())
lasso_wf_tune <- workflow() %>% 
  add_recipe(full_rec) %>% # recipe defined above
  add_model(lm_lasso_spec_tune) 

penalty_grid <- grid_regular(
  penalty(range = c(3, 7)), #log10 transformed 
  levels = 10)

nbatune_output <- tune_grid( # new function for tuning parameters
  lasso_wf_tune, # workflow
  resamples = nba_cv10, # cv folds
  metrics = metric_set(mae),
  grid = penalty_grid # penalty grid defined above
)

best_se_penalty <- select_by_one_std_err(nbatune_output, metric = 'mae', desc(penalty))
best_se_penalty

final_wf_se <- finalize_workflow(lasso_wf_tune, best_se_penalty) # incorporates penalty value to workflow

final_fit_se <- fit(final_wf_se, data = nba2021pergame)

tidy(final_fit_se)

glmnet_output <- final_fit_se %>% extract_fit_parsnip() %>% pluck('fit') # get the original glmnet output

lambdas <- glmnet_output$lambda
coefs_lambdas <- 
  coefficients(glmnet_output, s = lambdas )  %>% 
  as.matrix() %>%  
  t() %>% 
  as.data.frame() %>% 
  mutate(lambda = lambdas ) %>% 
  select(lambda, everything(), -`(Intercept)`) %>% 
  pivot_longer(cols = -lambda, 
               names_to = "term", 
               values_to = "coef") %>%
  mutate(var = purrr::map_chr(stringr::str_split(term,"_"),~.[1]))

coefs_lambdas %>%
  ggplot(aes(x = lambda, y = coef, group = term, color = var)) +
  geom_line() +
  geom_vline(xintercept = best_se_penalty %>% pull(penalty), linetype = 'dashed') + 
  theme_classic() + 
  theme(legend.position = "bottom", legend.text=element_text(size=8)) +
  xlim(0,7700000) + ylim(-2500000,5000000)
```


```{r}
nba2021per36 <- read.csv("Per36-Player.csv")


nba2021_2022salaries <- read.csv("2021-2022-Player-Salaries.csv")
names(nba2021_2022salaries)[1] <- "Player"

nba2021per36 <- nba2021per36 %>% left_join(nba2021_2022salaries,by=c('Player')) %>%
  select(-AllStar)  %>%
  distinct(Player, .keep_all = TRUE) %>%
  filter(!is.na(Salary)) %>%
  filter(MP > 300) %>%
  na.omit()
head(nba2021per36)
```

CLASSIFICATION
```{r}
tree_spec <- decision_tree() %>%
  set_engine(engine = 'rpart') %>%
  set_args(cost_complexity = tune(),  
           min_n = 2, 
           tree_depth = NULL) %>% 
  set_mode('classification') 

nba2021per36 <- nba2021per36 %>%
mutate(Pos = stringr::str_replace(stringr::str_sub(Pos,1,2),"-",""))

nba2021per36 <- nba2021per36 %>%
  mutate(Pos = as.factor(Pos))
  
data_fold <- vfold_cv(nba2021per36, v = 10)

data_rec <- recipe(Pos ~ FG +FGA + FT. + PTS +STL + BLK + ORB + DRB + AST + X3P. + X2P. + TOV, data = nba2021per36)

data_wf_tune <- workflow() %>%
  add_model(tree_spec) %>%
  add_recipe(data_rec)

param_grid <- grid_regular(cost_complexity(range = c(-5, -1)), levels = 10) 

tune_res <- tune_grid(
  data_wf_tune, 
  resamples = data_fold, 
  grid = param_grid, 
  metrics = metric_set(accuracy) #change this for regression trees
)

autoplot(tune_res) + theme_classic()

best_complexity <- select_by_one_std_err(tune_res, metric = 'accuracy', desc(cost_complexity))
best_complexity %>%
  pull(cost_complexity)
data_wf_final <- finalize_workflow(data_wf_tune, best_complexity)

pos_final_fit <- fit(data_wf_final, data = nba2021per36)


tune_res %>% 
  collect_metrics() %>%
  filter(cost_complexity == best_complexity %>% pull(cost_complexity))

tree_mod_lowcp <- fit(
    data_wf_tune %>%
        update_model(tree_spec %>% set_args(cost_complexity = .0001)),
    data = nba2021per36
)
tree_mod_highcp <- fit(
    data_wf_tune %>%
        update_model(tree_spec %>% set_args(cost_complexity = .018)),
    data = nba2021per36
)

# Plot all 3 trees in a row
#par(mfrow = c(1,3))
tree_mod_lowcp %>% extract_fit_engine() %>% rpart.plot()
pos_final_fit %>% extract_fit_engine() %>% rpart.plot()
tree_mod_highcp %>% extract_fit_engine() %>% rpart.plot()
```



```{r}
nba2021per36_sub <- nba2021per36 %>%
    select(STL, BLK, AST, TRB, FG., FT., X3PA)

# Run k-means for k = centers = 3
set.seed(253)
kclust_k5 <- kmeans(nba2021per36_sub, centers = 5)

# Display the cluter assignments
kclust_k5$cluster


nba2021per36 <- nba2021per36 %>%
    mutate(kclust_5 = factor(kclust_k5$cluster))
```

```{r}
set.seed(253)
kclust_k5_scale <- kmeans(scale(nba2021per36_sub), centers = 5)
nba2021per36 <- nba2021per36 %>%
    mutate(kclust_5_scale = factor(kclust_k5_scale$cluster))

# Visualize the new cluster assignments
ggplot(nba2021per36, aes(x=`BLK`, y= `AST`, color=kclust_5_scale)) +
    geom_point()
```

